---
layout: post
title: "notes fpp"
description: ""
category:
tags: [forecast]
Time-stamp: "liuminzhao 01/29/2014 13:08:04"
---
{% include JB/setup %}

Notes for Forecasting
=====================

<https://www.otexts.org/fpp/>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

# packages

- `forecast`
- `tseries`
- `fma` : ts data
- `expsmooth`: more ts data
- `lmtest`: some regression functions

# data

	beer <- window(ausbeer, start = 1992)

# Simple forecasting methods

## Average method:

	meanf(x, h = 20)

$$
y\_{T+h|T} = (y\_1 + ... + y\_T)/T
$$

## Naive method

	naive(x, h = 20)
	rwf(x, h= 20)

future equals the last one

$$
y\_{T+h|T} = y\_T
$$

## seasonal naive method

	snaive(x, h = 20)

$$
y\_{T+h|T} = y\_{T+h-km}
$$

## Drift method:

Equivalent to extrapolating a line drawn between first and last observations.

	rwf(x, drift = TRUE, h = 20)

$$
y\_{T+h|T} = y\_T + h/(T-1)*(y\_T - y\_1)
$$

# Measures of forecast accuracy

\begin{eqnarray}
MAE & = & T^{-1} \sum\_{t=1}^{T} abs(y\_t - yhat(t|t-1)) \\\
MSE & = & T^{-1} \sum\_{t=1}^{T} (y\_t - yhat(t|t-1))^2 \\\
MAPE & = & 100T^{-1} \sum\_{t=1}^{T} |(y\_t - yhat(t|t-1)|/|y\_t|
\end{eqnarray}

MAPE is scale independent.

Mean absolute scaled error (MASE)

# Training set vs test set

80% vs 20%

	beer3 <- window(ausbeer,start=1992,end=2005.99)
	beer4 <- window(ausbeer,start=2006)
	fit1 <- meanf(beer3,h=20)
	fit2 <- rwf(beer3,h=20)
	accuracy(fit1,beer4)
	accuracy(fit2,beer4)

Accuracy measures computed for errors in test set only.

# Time series graphics

	time plot: plot, plot.ts
	seasonal: seasonplot(beer, year.labels=TRUE)
	seasonal subseries: monthplot
	lag plot: lag.plot(beer, lags = 9)
	acf: Acf

# Autocorrelation

\begin{eqnarray}
c\_k & = 1/T * \sum\_{t = k+1}^T (y\_t - ybar)(y\_{t-k} - ybar) \\\
r\_k & = c\_k /c\_0
\end{eqnarray}

Can check $r\_1$ up to $r\_k$ to detect seasonal pattern

	Acf(beer)

Slowly decaying ACF indicates trend

ACF peaks at lags 12, 24, 36 indicate seasonality of length 12

# White Noise

Example of pigs slaughtered:

- Difficult to detect pattern in time plot.
- ACF shows some significant autocorrelation at lags 1, 2, and 3.
- r12 relatively large although not significant. This may indicate some slight seasonality.

These show the series is not a white noise series.

## Dow-Jones naive forecasts revisited

$$
yhat\_{t|t-1} = y\_{t-1}
$$

$$
e\_t = y\_t - y\_{t-1}
$$

check trace plot of $e\_t$ and ACF

# Pormanteau tests

## Box-Pierce test

$$
Q = T \sum\_{k=1}^h r\_k^2
$$

- `h=10`  for non-seasonal data, $h=2m$ for seasonal data, is max lag being considered
- `T` is number of observations
- if $r$ close to zero, then Q will be small
- if some $r$ is large, then Q will be large

## Ljung-Box test

$$
Q^* = T(T+2) \sum\_{k=1}^h (T-k)^{-1} r\_k^2
$$

better performance, especially in small samples.

If white noise, $Q^*$ has chi-square distribution with $(h-K)$ df where $K$ is number of parameters in model(for raw data, K=0)

	Box.test(res, lag = 10, fitdf = 0)
	Box.test(res, lag = 10, fitdf = 0, type = "Lj")

test residual

	beer <- window(ausbeer,start=1992)
	fc <- snaive(beer)
	res <- residuals(fc)
	Acf(res)
	Box.test(res, lag=8, fitdf=0, type="Lj")

# Time series decomposition

$$
Y\_t = f(S\_t, T\_t, E\_t)
$$

$S\_t$: seasonal component

$T\_t$: trend-cycle component

## STL

	stl()
	decompose()

	plot(decompose(hsales))
	plot(stl(hsales,s.window="periodic"))
	plot(stl(hsales,s.window=15))

	fit = stl(data, s.window=5, t.window=15, s.window = "periodic")
	plot(fit)

	t.window: controls wiggliness of trend
	s.window: controls variation in seasonal component

## Seasonal adjustment

	plot(hsales,col="gray")
	fit <- stl(hsales,s.window=15)
	hsales.sa <- seasadj(fit)
	lines(hsales.sa, col="red")

	fit <- stl(elecequip, t.window=15,
	s.window="periodic", robust=TRUE)
	eeadj <- seasadj(fit)
	plot(naive(eeadj), xlab="New orders index")
	fcast <- forecast(fit, method="naive")
	plot(fcast, ylab="New orders index")

# Exponential smoothing

	ses(x) : simple exponential smoothing, no trend
	holt(x): Hold's method: linear trend
	holt(x, exponential = TRUE):  exponential trend method
	holt(x, damped = TRUE): damped trend method
	holt(x, damped = TRUE, exponential = TRUE)

## simple exponential smoothing

### random walk forecasts

$$
y\_{T+1|T} = y\_T
$$

### average

$$
y\_{T+1|T} = 1/T * \sum\_{t=1}^T y\_t
$$

### simple exponential smoothing

$$
y\_{T+1|T} = \alpha y\_T + \alpha(1-\alpha) y\_{T-1} + \alpha(1-\alpha)^2 y\_{T-2} +
$$

weighted average form

$$
y\_{T+1|T} = \alpha y\_T + \alpha(1-\alpha) y\_{T-1}
$$

Exponentially weighted average:

$$
y\_{T+1|T} = \sum\_{j=0}^{T-1} \alpha(1-\alpha)^j y\_{T-j} + (1-\alpha)^T l\_0
$$

Common to set $l\_0 = y\_1$

### optimization

can choose $\alpha$ and $l\_0$ by minimizing MSE:

$$
MSE = 1/(T-1) \sum\_{t=2}^T (y\_t- y\_{t|t-1})^2
$$

No closed form, use numerical result

### SES in R

	fit1 <- ses(oildata, alpha=0.2,
            initial="simple", h=3)
	fit2 <- ses(oildata, alpha=0.6,
    initial="simple", h=3)
	fit3 <- ses(oildata, h=3)
	accuracy(fit1)
	accuracy(fit2)
	accuracy(fit3)

## Non-seasonal trend methods

### Holt's local trend method

\begin{eqnarray}
yhat\_{t+h|t}& = l\_t + h\*b\_t \\\
l\_t &= \alpha\*y\_t + (1 - \alpha)(l\_{t-1} + b\_{t-1})\\\
b\_t &= \beta^* (l\_t - l\_{t-1}) + (1 - \beta^*) b\_{t-1}
\end{eqnarray}

find $\alpha$ and $\beta^*$ by minimizing the MSE

	fit1 <- holt(strikes)
	plot(fit1$model)
	plot(fit1, plot.conf=FALSE)
	lines(fitted(fit1), col="red")
	fit1$model
	fit2 <- ses(strikes)
	plot(fit2$model)
	plot(fit2, plot.conf=FALSE)
	lines(fit1$mean, col="red")
	accuracy(fit1)
	accuracy(fit2)

### Exponential one

	yˆt+h|t = ltbht
	lt = αyt + (1 − α)(lt−1bt−1)
	bt =β∗(lt/lt−1)+(1−β∗)bt−1

bt : relative growth

### damped trend

\begin{eqnarray}
yhat\_{t+h|t} &= l\_t + (\phi + \phi^2 + ... + \phi^(h-1))\*b\_t \\\
l\_t &= \alpha\*y\_t + (1 - \alpha)(l\_{t-1} + \phi\* b\_{t-1}) \\\
b\_t &= \beta^* (l\_t - l\_{t-1}) + (1 - \beta^{\*}) \phi\* b\_{t-1}
\end{eqnarray}

phi damped the trend so it approaches a constant

Damped trend method often gives better forecasts than linear trend.

## Holt-Winters

- capture seasonality

###  additive method

\begin{eqnarray}
y(t+h|t) &=&  l\_t + hb\_t + s\_{t−m+h^+m} \\\
l\_t &=&  α(y\_t − s\_{t−m}) + (1 − α)(l\_{t−1} + b\_{t−1}) \\\
b\_t &=&  β∗(l\_t − l\_{t−1}) + (1 − β∗)b\_{t−1} \\\
s\_t &=& γ(yt −l\_{t−1} −b\_{t−1})+(1−γ)s\_{t−m} \\\
h\_m^+ &=& ⌊(h−1) mod m⌋+1
\end{eqnarray}

### Multiplicative model

\begin{eqnarray}
y(t+h|t) &=&  (l\_t + hb\_t)s\_{t−m+h^+m} \\\
l\_t &=&  α(y\_t/s\_{t−m}) + (1 − α)(l\_{t−1} + b\_{t−1}) \\\
b\_t &=&  β∗(l\_t − l\_{t−1}) + (1 − β∗)b\_{t−1} \\\
s\_t &=& γ(yt/(l\_{t−1}+b\_{t−1}))+(1−γ)s\_{t−m} \\\
h\_m^+ &=& ⌊(h−1) mod m⌋+1
\end{eqnarray}

optimze

	alpha, beta*, gamma, l_0, b_0, s_0, s_-1, ..., s_{1-m}

## Damped Holt-winters Multiplicative method

\begin{eqnarray}
y(t+h|t) &=&  (l\_t + (1+phi+...+phi^{h-1})b\_t)s\_{t−m+h^+m} \\\
l\_t &=&  α(y\_t/s\_{t−m}) + (1 − α)(l\_{t−1} + b\_{t−1}) \\\
b\_t &=&  β∗(l\_t − l\_{t−1}) + (1 − β∗)b\_{t−1} \\\
s\_t &=& γ(yt/(l\_{t−1}+b\_{t−1}))+(1−γ)s\_{t−m} \\\
h\_m^+ &=& ⌊(h−1) mod m⌋+1
\end{eqnarray}

## ETS(Error, Trend, Seasonal)

| Trend                     | N                  | A    | M    |
|---------------------------|--------------------|------|------|
| N                         | N,N                | N,A  | N,M  |
| A(additive)               | A,N                | A,A  | A,M  |
| Ad(additive damped)       | Ad,N               | Ad,A | Ad,M |
| M(multiplicative)         | M,N                | M,A  | M,M  |
| Md(multiplicative damped) | Md,N               | Md,A | Md,M |

### R functions

	ses(): (N,N)
	holt(): (A, N), (Ad, N), (M,N), (Md,N)
	hw(): (A,A), (Ad, A), (A,M), (Ad,M), (M,M), (Md,M)

# Exponential smoothing state space models (`forecast` package)

Previous models do not use the likelihood.

State space models adopt distributional assumptions and can be estimated by MLE. Can alos do model comparison by AIC.

Showed All ES methods (including non-linear methods) are optimal forecasts from innovations state space models. See Hyndman et al (2008) for a comprehensive survey

	ETS(A,N,N): simple exponential smoothing with additive errors
	ETS(A,A,N): Holt's linear method with additive errors
	ETS(A,A,A): additive Holt-winters method with additive errors
	ETS(M,A,M): Multiplicative Holt-winters' method with multiplicative errors
	ETS(A,Ad,N): damped trend method with additive errors

## Innovative state space models

- All the methods can be written in this state space form.
- Prediction intervals can be obtained by simulating many future sample paths.
- For many models, the prediction intervals can be obtained analytically as well.
- Additive and multiplicative versions give the same point forecasts.
- Estimation is handled via maximizing the likelihood of the data given the model.

## AIC

	AIC = -2 log(L) + 2p

AIC corrected( for small sample bias)

	AIC = AIC + 2(p+1)(p+2)/(n-p)

- A difference in AIC values of 2 or less is not regarded as substantial and you may choose the simpler but non-optimal model.

## BIC

	BIC = -2 log(L) + p*log(n)

# Procedures

From Hyndman et al (2008):

- Apply each of 30 methods that are appropriate to the data. Estimate parameters and initial values using MLE.
- Select best method using AIC. Produce forecasts using best method.
- Obtain prediction intervals using underlying state space model.

Sample R code:

	fit <- ets(ausbeer)
	fit2 <- ets(ausbeer,model="AAA",damped=FALSE)
	fcast1 <- forecast(fit, h=20)
	fcast2 <- forecast(fit2, h=20)
	ets(y, model="ZZZ", damped=NULL, alpha=NULL,
    beta=NULL, gamma=NULL, phi=NULL,
    additive.only=FALSE,
    lower=c(rep(0.0001,3),0.80),
    upper=c(rep(0.9999,3),0.98),
    opt.crit=c("lik","amse","mse","sigma"), nmse=3,
    bounds=c("both","usual","admissible"),
    ic=c("aic","aicc","bic"), restrict=TRUE)

`ets()` function:

- Automatically chooses a model by default using the AIC, AICc or BIC.
- Can handle any combination of trend, seasonality and damping
- Produces prediction intervals for every model
- Ensures the parameters are admissible (equivalent to invertible)
- Produces an object of class ets.

functions

	plot(fit)
	accuracy(fit)

- `forecast` returns forecasts when applied to an ets object (or the output from many other time series models).
- If you use `forecast` directly on data, it will select an ETS model automatically and then return forecasts.
